{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path \n",
    "import numpy \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "matplotlib.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/validation test dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self): #len(val_dataset)\n",
    "        return len(self.pkl_list)\n",
    "    \n",
    "    def __getitem__(self, idx): #val_dataset[0]\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArgoverseDataset(data_path=train_path) \n",
    "test_dataset  = ArgoverseDataset(data_path=test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205942"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ca6c582ce042b0b8ef75e5630217a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "in_train, out_train = [], []\n",
    "for i in tqdm(range(0, 200000)):\n",
    "    val = train_dataset[i]\n",
    "    p_in = val['p_in'][val['car_mask'].reshape(-1) == 1]\n",
    "    p_out = val['p_out'][val['car_mask'].reshape(-1) == 1]\n",
    "    for c in range(len(p_in)):\n",
    "        in_train.append(p_in[c].reshape(19*2))\n",
    "        out_train.append(p_out[c].reshape(30*2))\n",
    "in_train = np.array(in_train)\n",
    "out_train = np.array(out_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8116fa44f6da4b369cb8434e4ae7bcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "in_valid, out_valid = [], []\n",
    "for i in tqdm(range(200000-1, 205942)):\n",
    "    val = train_dataset[i]\n",
    "    p_in = val['p_in'][val['car_mask'].reshape(-1) == 1]\n",
    "    p_out = val['p_out'][val['car_mask'].reshape(-1) == 1]\n",
    "    for c in range(len(p_in)):\n",
    "        in_valid.append(p_in[c].reshape(19*2))\n",
    "        out_valid.append(p_out[c].reshape(30*2))\n",
    "in_valid = np.array(in_valid)\n",
    "out_valid = np.array(out_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in_train = in_train[:, list(range(0, 38, 2))]\n",
    "y_in_train = in_train[:, list(range(1, 39, 2))]\n",
    "\n",
    "x_out_train = out_train[:, list(range(0, 60, 2))]\n",
    "y_out_train = out_train[:, list(range(1, 61, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1760155, 19), (1760155, 19), (1760155, 30), (1760155, 30))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in_train.shape, y_in_train.shape, x_out_train.shape, y_out_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in_valid = in_valid[:, list(range(0, 38, 2))]\n",
    "y_in_valid = in_valid[:, list(range(1, 39, 2))]\n",
    "\n",
    "x_out_valid = out_valid[:, list(range(0, 60, 2))]\n",
    "y_out_train = out_valid[:, list(range(1, 61, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9999999720564747\n",
      "1 0.9999998606835677\n",
      "2 0.9999995591729811\n",
      "3 0.9999990666000739\n",
      "4 0.9999983731784919\n",
      "5 0.9999975046702431\n",
      "6 0.999996436367472\n",
      "7 0.9999951806544309\n",
      "8 0.9999937327352634\n",
      "9 0.999992081261241\n",
      "10 0.9999902376357248\n",
      "11 0.9999882150271086\n",
      "12 0.9999859938986253\n",
      "13 0.9999835605996417\n",
      "14 0.9999809603371024\n",
      "15 0.9999781402339497\n",
      "16 0.999975159806497\n",
      "17 0.9999719303981158\n",
      "18 0.9999685486390444\n",
      "19 0.9999649747719512\n",
      "20 0.9999611945165718\n",
      "21 0.9999571666565411\n",
      "22 0.9999529929593971\n",
      "23 0.9999486070940553\n",
      "24 0.9999440279500589\n",
      "25 0.9999392402715116\n",
      "26 0.9999343095449696\n",
      "27 0.9999291747872935\n",
      "28 0.999923934296924\n",
      "29 0.9999185352651137\n"
     ]
    }
   ],
   "source": [
    "#Use that 19 time points to predict every future points: \n",
    "#obviously should be lower than the final LR\n",
    "for i in range(30):\n",
    "    print(i, reg.score(x_in_valid, x_out_valid[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = [LinearRegression()] * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d24a935fa84a3486f4d1016f553c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "regs[0] = LinearRegression().fit(x_in_train, x_out_train[:, 0])\n",
    "pred = regs[0].predict(x_in_train)\n",
    "x_in_train = np.insert(x_in_train, 19 + 0, pred, axis=1)\n",
    "\n",
    "for i in tqdm(range(1, 30)):\n",
    "    regs[i] = LinearRegression().fit(x_in_train, x_out_train[:, i])\n",
    "    pred = regs[i].predict(x_in_train)\n",
    "    x_in_train = np.insert(x_in_train, 19 + i, pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1760155, 49)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set: what is the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999706316878\n",
      "0.9999999522101889\n",
      "0.9999999314364197\n",
      "0.9999999059040638\n",
      "0.9999998734611978\n",
      "0.9999998341014829\n",
      "0.9999997857053922\n",
      "0.9999997270690452\n",
      "0.9999996569478273\n",
      "0.9999995749600455\n",
      "0.9999994801562861\n",
      "0.9999993694394474\n",
      "0.9999992415629441\n",
      "0.9999990980554518\n",
      "0.9999989351657506\n",
      "0.9999987506079562\n",
      "0.9999985441856927\n",
      "0.9999983148635783\n",
      "0.9999980609190324\n",
      "0.9999977815631815\n",
      "0.9999974716478127\n",
      "0.9999971361935339\n",
      "0.9999967684914657\n",
      "0.9999963682304969\n",
      "0.9999959328154526\n",
      "0.9999954634669268\n",
      "0.9999949583667719\n",
      "0.9999944146837969\n",
      "0.9999938356211475\n",
      "0.9999932219293578\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(r2_score(x_in_train[:, 19 + i], x_out_train[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New: Train test split for the difference in location approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArgoverseDataset(data_path=train_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d04411d7b1d41aa82e8cbc024bc0f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=205942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#diff points\n",
    "\n",
    "train = []\n",
    "for i in tqdm(range((len(train_dataset)))):\n",
    "    val = train_dataset[i]\n",
    "    c_filter = val['car_mask'].reshape(-1) == 1\n",
    "    p_in = val['p_in'][c_filter]\n",
    "    p_out = val['p_out'][c_filter]\n",
    "    for c in range(len(p_in)):\n",
    "        in_out = np.diff(np.vstack((p_in[c], p_out[c])), axis=0).flatten()\n",
    "        train.append(in_out)\n",
    "train = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449736.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) * 0.8 //1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449736, 96)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:int(len(train) * 0.8 //1), :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(len(train) * 0.8 //1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ = train[int(len(train) * 0.8 //1):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train, out_train = train_[:, :36], train_[:, 36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706e7e67703a4a4dbca31a3bcaf638c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5ab5b5af1f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#append GT back to the train feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0min_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_end_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   4591\u001b[0m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4592\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4593\u001b[0;31m         \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4594\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnumnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4595\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#auto regressive and teacher-forcing\n",
    "\n",
    "#prepare a list of 60 linear regression models, half for 30 output x, half for 30 output y\n",
    "\n",
    "num_output = 60\n",
    "input_end_idx = 36\n",
    "\n",
    "regs = [None] * num_output\n",
    "\n",
    "#train using labels from the ground truth output, and use the GT output to train new time point\n",
    "for i in tqdm(range(num_output)):\n",
    "    regs[i] = LinearRegression().fit(in_train, out_train[:, i])\n",
    "    \n",
    "    #append GT back to the train feature\n",
    "    in_train = np.insert(in_train, input_end_idx + i, out_train[:, i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
